{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "27e9131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing python libraries\n",
    "from pydantic import Field,BaseModel\n",
    "from typing import Annotated\n",
    "from IPython.display import display,Image\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import gradio as gr\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c51922d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing langchain,langgraph\n",
    "from langgraph.graph import StateGraph,START,END,add_messages\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langgraph.prebuilt import tools_condition,ToolNode\n",
    "from langchain.agents import Tool\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "1786af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbpath = './memory/memory.db'\n",
    "dbconn = sqlite3.connect(dbpath,check_same_thread=False)\n",
    "sql_memory = SqliteSaver(dbconn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e0b52de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_model = google_model = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "beafa7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "dec1e5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "71efa2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "serper = GoogleSerperAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7020c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(BaseModel):\n",
    "    messages : Annotated[list,add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f22e413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool =Tool(\n",
    "    name=\"searchTool\",\n",
    "    func=serper.run,\n",
    "    description=\"searching\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ae4f8bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "394792dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c7476e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(api_key=gemini_api_key,model=gemini_model)\n",
    "tools = [search_tool]\n",
    "llm_as_tool = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dfb63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_bot(state:State)->State:\n",
    "    result= llm_as_tool.invoke(state.messages)\n",
    "    return State(messages=[result])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "729c3a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1ca3476d8b0>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_node(\"chatbot\",chat_bot)\n",
    "graph_builder.add_node(\"tools\",ToolNode(tools=tools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a4571a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1ca3476d8b0>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_conditional_edges(\"chatbot\",tools_condition,\"tools\")\n",
    "graph_builder.add_edge(\"tools\",\"chatbot\")\n",
    "graph_builder.add_edge(START,\"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c4c2bf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=sql_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "792f9437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Could not render PNG. Showing Mermaid text only.\n",
      "Error: Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 204.\n",
      "\n",
      "To resolve this issue:\n",
      "1. Check your internet connection and try again\n",
      "2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n",
      "3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    png_bytes = graph.get_graph().draw_mermaid_png()\n",
    "    display(Image(data=png_bytes))\n",
    "except Exception as e:\n",
    "    print(\"⚠️ Could not render PNG. Showing Mermaid text only.\")\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497e1676",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"thread_id\":\"1\"}}\n",
    "def chat(user_input,history):\n",
    "    result = graph.invoke(State(messages=[{\"role\":\"user\",\"content\":user_input}]),config=config)\n",
    "    return result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8345fa4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The `type` parameter must be 'messages' or 'tuples', received: message",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[219]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChatInterface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.launch()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Learning\\GenAIGunjanProjects\\GenAIFundamentals\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py:285\u001b[39m, in \u001b[36mChatInterface.__init__\u001b[39m\u001b[34m(self, fn, multimodal, type, chatbot, textbox, additional_inputs, additional_inputs_accordion, additional_outputs, editable, examples, example_labels, example_icons, run_examples_on_click, cache_examples, cache_mode, title, description, theme, flagging_mode, flagging_options, flagging_dir, css, css_paths, js, head, head_paths, analytics_enabled, autofocus, autoscroll, submit_btn, stop_btn, concurrency_limit, delete_cache, show_progress, fill_height, fill_width, api_name, api_description, show_api, save_history, validator)\u001b[39m\n\u001b[32m    283\u001b[39m                 \u001b[38;5;28mself\u001b[39m._render_footer()\n\u001b[32m    284\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_render_chatbot_area\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchatbot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtextbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubmit_btn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_btn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    286\u001b[39m         \u001b[38;5;28mself\u001b[39m._render_footer()\n\u001b[32m    288\u001b[39m \u001b[38;5;28mself\u001b[39m._setup_events()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Learning\\GenAIGunjanProjects\\GenAIFundamentals\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py:348\u001b[39m, in \u001b[36mChatInterface._render_chatbot_area\u001b[39m\u001b[34m(self, chatbot, textbox, submit_btn, stop_btn)\u001b[39m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    347\u001b[39m     \u001b[38;5;28mself\u001b[39m.type = \u001b[38;5;28mself\u001b[39m.type \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtuples\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m     \u001b[38;5;28mself\u001b[39m.chatbot = \u001b[43mChatbot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mChatbot\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m400\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfill_height\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLiteral\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtuples\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m        \u001b[49m\u001b[43mautoscroll\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mautoscroll\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexamples_messages\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_additional_inputs_in_examples\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Group():\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Row():\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Learning\\GenAIGunjanProjects\\GenAIFundamentals\\.venv\\Lib\\site-packages\\gradio\\component_meta.py:189\u001b[39m, in \u001b[36mupdateable.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Learning\\GenAIGunjanProjects\\GenAIFundamentals\\.venv\\Lib\\site-packages\\gradio\\components\\chatbot.py:302\u001b[39m, in \u001b[36mChatbot.__init__\u001b[39m\u001b[34m(self, value, type, label, every, inputs, show_label, container, scale, min_width, visible, elem_id, elem_classes, autoscroll, render, key, preserved_by_key, height, resizable, resizeable, max_height, min_height, editable, latex_delimiters, rtl, show_share_button, show_copy_button, watermark, avatar_images, sanitize_html, render_markdown, feedback_options, feedback_value, bubble_full_width, line_breaks, layout, placeholder, examples, show_copy_all_button, allow_file_downloads, group_consecutive_messages, allow_tags)\u001b[39m\n\u001b[32m    296\u001b[39m     warnings.warn(\n\u001b[32m    297\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtuples\u001b[39m\u001b[33m'\u001b[39m\u001b[33m format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m\u001b[33m instead, which uses openai-style \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m\u001b[33m keys.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    298\u001b[39m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    299\u001b[39m         stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    300\u001b[39m     )\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtuples\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    303\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe `type` parameter must be \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtuples\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    304\u001b[39m     )\n\u001b[32m    305\u001b[39m \u001b[38;5;28mself\u001b[39m.type: Literal[\u001b[33m\"\u001b[39m\u001b[33mtuples\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mtype\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;28mself\u001b[39m._setup_data_model()\n",
      "\u001b[31mValueError\u001b[39m: The `type` parameter must be 'messages' or 'tuples', received: message"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat,type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b547a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaifundamentals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
