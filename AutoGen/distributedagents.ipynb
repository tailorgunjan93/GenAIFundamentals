{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43f3e7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from autogen_ext.tools.langchain import LangChainToolAdapter\n",
    "from langchain.agents import Tool\n",
    "from autogen_core import AgentId,MessageContext,RoutedAgent,message_handler\n",
    "from autogen_ext.runtimes.grpc import GrpcWorkerAgentRuntimeHost,GrpcWorkerAgentRuntime\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a691231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "gemini_model  = \"gemini-2.0-flash\"\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "gemini_client = OpenAIChatCompletionClient(model=gemini_model,api_key=gemini_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4146774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Message():\n",
    "    content : str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "560fef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "serp = GoogleSerperAPIWrapper()\n",
    "lang_tool = Tool(name=\"serper\",func=serp.run,description=\"useful tool for google searches\")\n",
    "auto_gen_tool =LangChainToolAdapter(lang_tool)\n",
    "tools = [auto_gen_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df98c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player1(RoutedAgent):\n",
    "    def __init__(self,name:str)->None:\n",
    "        super().__init__(name)\n",
    "        self._delegate = AssistantAgent(name,model_client=gemini_client,tools=tools,reflect_on_tool_use=True)\n",
    "   \n",
    "    @message_handler\n",
    "    async def handle_message(self,message:Message,ctx:MessageContext)->Message:\n",
    "        text_message = TextMessage(content=message.content,source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message],cancellation_token=ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "729a0374",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player2(RoutedAgent):\n",
    "    def __init__(self,name:str)->None:\n",
    "        super().__init__(name)\n",
    "        self._delegate = AssistantAgent(name,model_client=gemini_client,tools=tools,reflect_on_tool_use=True)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_message(self,message:Message,ctx:MessageContext)->Message:\n",
    "        text_message = TextMessage(content=message.content,source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message],cancellation_token=ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c58a6dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction1 = \"To help with a decision on whether to use AutoGen in a new AI Agent project, \\\n",
    "please research and briefly respond with reasons in favor of choosing AutoGen; the pros of AutoGen.\"\n",
    "\n",
    "instruction2 = \"To help with a decision on whether to use AutoGen in a new AI Agent project, \\\n",
    "please research and briefly respond with reasons against choosing AutoGen; the cons of Autogen.\"\n",
    "\n",
    "judge = \"You must make a decision on whether to use AutoGen for a project. \\\n",
    "Your research team has come up with the following reasons for and against. \\\n",
    "Based purely on the research from your team, please respond with your decision and brief rationale.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb0975b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Judge(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        \n",
    "        self._delegate = AssistantAgent(name, model_client=gemini_client)\n",
    "        \n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        message1 = Message(content=instruction1)\n",
    "        message2 = Message(content=instruction2)\n",
    "        inner_1 = AgentId(\"player1\", \"default\")\n",
    "        inner_2 = AgentId(\"player2\", \"default\")\n",
    "        response1 = await self.send_message(message1, inner_1)\n",
    "        response2 = await self.send_message(message2, inner_2)\n",
    "        result = f\"## Pros of AutoGen:\\n{response1.content}\\n\\n## Cons of AutoGen:\\n{response2.content}\\n\\n\"\n",
    "        judgement = f\"{judge}\\n{result}Respond with your decision and brief explanation\"\n",
    "        message = TextMessage(content=judgement, source=\"user\")\n",
    "        response = await self._delegate.on_messages([message], ctx.cancellation_token)\n",
    "        return Message(content=result + \"\\n\\n## Decision:\\n\\n\" + response.chat_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2cc7a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_IN_ONE_WORKER = False\n",
    "host = GrpcWorkerAgentRuntimeHost(address=\"localhost:50051\")\n",
    "host.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cad66039",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ALL_IN_ONE_WORKER:\n",
    "    worker = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker.start()\n",
    "    await Player1.register(worker,\"player1\",lambda:Player1(\"player1\"))\n",
    "    await Player2.register(worker,\"player2\",lambda:Player2(\"player2\"))\n",
    "    await Judge.register(worker,\"judge\",lambda:Judge(\"judge\"))\n",
    "    agent_id = AgentId(\"judge\",\"default\")\n",
    "else:\n",
    "    worker1 = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker1.start()\n",
    "    await Player1.register(worker1,\"player1\",lambda:Player1(\"player1\"))\n",
    "\n",
    "    worker2 = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker2.start()\n",
    "    await Player2.register(worker2,\"player2\",lambda:Player2(\"player2\"))\n",
    "\n",
    "    worker = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker.start()\n",
    "    await Judge.register(worker,\"judge\",lambda:Judge(\"judge\"))\n",
    "    agent_id = AgentId(\"judge\",\"default\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ac5b024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Pros of AutoGen:\n",
       "Here are some reasons to choose AutoGen for your new AI Agent project, highlighting its pros:\n",
       "\n",
       "*   **Complex Automation & Dynamic Environments:** AutoGen excels in scenarios requiring complex automation and adaptation to dynamic environments. It's suitable for tasks that go beyond simple, pre-defined workflows.\n",
       "*   **Multi-Agent Collaboration:** AutoGen is designed for orchestrating multiple AI agents that can collaborate to solve problems. This allows for a division of labor and more sophisticated problem-solving approaches.\n",
       "*   **Customization:** The framework offers a high degree of customization, allowing you to tailor the agents and their interactions to your specific needs.\n",
       "*   **Reduced Coordination Complexity:** Natural language handoffs between agents simplify inter-agent communication, eliminating the need for custom protocols and streamlining the development process.\n",
       "*   **Memory and Learning:** AutoGen supports persistent memory, enabling agents to recall past tasks, user preferences, and learn over time.\n",
       "*   **LLM Optimization:** AutoGen enables you to efficiently utilize multiple large language models (LLMs) and tools.\n",
       "*   **Open-Source and Flexible:** Being open-source, AutoGen provides flexibility and community support.\n",
       "\n",
       "TERMINATE\n",
       "\n",
       "\n",
       "## Cons of AutoGen:\n",
       "Here are some cons to consider when deciding whether to use AutoGen for your AI Agent project:\n",
       "\n",
       "*   **Overkill for Simple Tasks:** AutoGen is designed for complex collaborative tasks. If your project involves simple, straightforward tasks, AutoGen might be more complex than necessary.\n",
       "*   **Steeper Learning Curve:** The flexibility and customization options can lead to a steeper learning curve compared to simpler frameworks. Understanding how to configure and manage multiple agents and their interactions requires more effort.\n",
       "*   **Debugging Complexity:** When multiple agents interact, debugging issues can become complex. Tracing the flow of information and identifying the source of errors across different agents can be challenging.\n",
       "*   **Resource Intensive:** Managing and running multiple collaborating agents can be more resource-intensive than single-agent systems, potentially requiring more powerful hardware and computational resources.\n",
       "*   **Lack of Visual Builder/No-Code Interface:** AutoGen doesn't offer visual builders or no-code interfaces, making it less accessible to users without strong coding skills.\n",
       "*   **Complexity in Prompt Engineering:** Effective collaboration between agents relies heavily on well-designed prompts. Crafting prompts that ensure agents understand their roles, communicate effectively, and avoid conflicts can be intricate.\n",
       "*   **Potential for Unexpected Behavior:** The dynamic interaction between multiple agents can sometimes lead to unexpected or undesirable behavior, especially if the agents' goals are not perfectly aligned or their communication is not carefully managed.\n",
       "\n",
       "TERMINATE\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "## Decision:\n",
       "\n",
       "Based on the provided pros and cons, I will proceed with using AutoGen for the project if and only if the project requires complex automation, multi-agent collaboration, and dynamic adaptation. The key deciding factors are the need for these advanced features, balanced against the increased complexity in learning, debugging, and resource requirements. If the project involves only simple tasks, AutoGen is likely overkill. If the project needs to leverage multiple LLMs and tools and agents need to learn and remember context AutoGen may also be more useful than other frameworks.\n",
       "TERMINATE\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display,Markdown\n",
    "response = await worker.send_message(Message(content=\"GO!\"),agent_id)\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c4b96b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "await worker.stop()\n",
    "if not ALL_IN_ONE_WORKER:\n",
    "    await worker1.stop()\n",
    "    await worker2.stop()\n",
    "await host.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826b49a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaifundamentals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
