{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5804eace",
   "metadata": {},
   "source": [
    "# User Input and GPT Messages\n",
    "\n",
    "This section demonstrates how to interact with the user by accepting input and displaying responses generated by GPT.  \n",
    "Markdown cells like this one are used to provide explanations, instructions, and context for the code and outputs in your Jupyter Notebook.  \n",
    "By documenting your workflow, you make your notebook more readable and easier to follow for others or for your future self.\n",
    "\n",
    "Below, you will see examples of how user input is collected and how GPT-generated messages are displayed, helping to create an interactive and informative experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8353e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyCuwzCzpSEhUY_n2tA1ODhHYYQhQkCJUFU\n"
     ]
    }
   ],
   "source": [
    "#import liberaries\n",
    "import dotenv\n",
    "import os\n",
    "import config\n",
    "from openai import OpenAI\n",
    "#load env variables\n",
    "dotenv.load_dotenv(override=True)\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "print(gemini_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7881de27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to take user input and print response\n",
    "def chat_with_gemini(user_input):\n",
    "    #prepare user message\n",
    "    message = [{\"role\": \"user\", \"content\": user_input}]\n",
    "    #initialize the openai client\n",
    "    gen_ai = OpenAI(api_key=gemini_api_key, base_url=config.GEMINI_URL_OPEN_AI)\n",
    "    #send the message to the genai chat model and get a response\n",
    "    response = gen_ai.chat.completions.create(\n",
    "        model=config.GEMINI_FLASH_MODEL_NAME,\n",
    "        messages=message\n",
    "    )\n",
    "    #print the ai's response to the user's message\n",
    "    print(\"AI:\"+response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a90c944a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:Hello there! How can I help you today?\n",
      "\n",
      "AI:I am a large language model, trained by Google.\n",
      "\n",
      "Exiting the chat. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "#now take user input untill user types 'exit'\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        print(\"Exiting the chat. Goodbye!\")\n",
    "        break\n",
    "    chat_with_gemini(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557bd0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaifundamentals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
